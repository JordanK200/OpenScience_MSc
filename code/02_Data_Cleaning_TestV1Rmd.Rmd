---
title: "02_Data_Cleaning"
author: "Jordan Katchen"
date: "2026-01-23"
output: html_document
---


# Introduction

This file cleans and merges the raw PLOS data, CIHR funding data, and NSERC funding data.

# Library

```{r}
library(tidyverse)
library(rcrossref)
library(readxl)
library(textclean)
library(humaniformat)
library(stringi)
library(googledrive)
library(here)
library(openalexR)
```

# Data Download

For now, I've uploaded the raw data to a public Google drive. The following code chunk first checks to see if these raw files have already been downloaded locally, and if not, it downloads them from the Google drive to data/raw-data directory.

The NSERC and CIHR raw data can also be easily downloaded using the `01_CIHR_scrape.R` and `01_NSERC_scrape.R` scripts.

Data can be found: https://drive.google.com/drive/folders/1FSxIsOkGuVqUTiFzEPaC4xpr_r5OvzNJ?usp=sharing

```{r}
# --- Define Files ---
# For each file: Google Drive ID and local path
files <- list(
  list(id = "https://drive.google.com/file/d/1JPSHpU8EMPeviTDvPFmbX4Nua6gcUcd4/view?usp=sharing", path = here("data", "raw-data", "RAW_PLOS.csv")),
  list(id = "https://drive.google.com/file/d/1v9Ho0FVOsazANgoNBgFRqKMzxdUwiTwy/view?usp=sharing", path = here("data", "raw-data", "RAW_PLOS_Comparator.csv")),
  list(id = "https://drive.google.com/file/d/1p9VTGlxzndML6PDjCJ_r4Ve4ku1RXVOV/view?usp=share_link", path = here("data", "raw-data", "RAW_NSERC.csv")),
  list(id = "https://drive.google.com/file/d/15UPWi0FlDIoxv2KjB6zhQk3CRHrzUxXv/view?usp=share_link", path = here("data", "raw-data", "RAW_CIHR.csv"))
)

# Use deauth() so public files can be downloaded without logging in
drive_deauth()

# Now download files
walk(files, ~{
  if (!file.exists(.x$path)) {
    message("Downloading: ", .x$path)
    drive_download(as_id(.x$id), path = .x$path, overwrite = FALSE)
  } else {
    message("Already exists: ", .x$path)
  }
})

rm(files) # Removing files list
```

# PLOS Data Cleaning

Loading the main PLOS data and comparator data.
```{r}
PLOS_Main <- read.csv(here("data", "raw-data", "RAW_PLOS.csv"))
PLOS_Comparator <- read.csv(here("data", "raw-data", "RAW_PLOS_Comparator.csv"))
```

Combining the main PLOS data with the PLOS comparator data.
```{r}
# First add a new column to distinguish the data sets.
PLOS_Main <- mutate(PLOS_Main, source = "PLOS")
PLOS_Comparator <- mutate(PLOS_Comparator, source = "Comparator")

# Now combine data
PLOS_Data <- bind_rows(PLOS_Main, PLOS_Comparator)
```

Because we are only interested in Canadian research, remove all rows without a Canadian corresponding author or first author.
```{r}
PLOS_Data <- PLOS_Data %>%
  filter(Corresponding_Author_Country == "Canada" | First_Author_Country == "Canada")
```

Fetch Open Alex metadata using study DOIs.
```{r}
OA_PLOS_Data <- oa_fetch(doi = PLOS_Data$DOI)
```

Isolate author and institution information from Open Alex search. This results in having a single row for each publication, author, institution combination.
```{r}
OA_PLOS_Data <- OA_PLOS_Data %>%
  select(doi, authorships) %>%
  unnest(authorships) %>%
  rename(author_id = id, author_display_name = display_name) %>%
  unnest(affiliations) %>%
  rename(institution = id, institution_display_name = display_name)
```

Use `parse_names()` to split author names into components. Using the `parse_names()` function allows us to have a consistent method of formatting author names across all data sets.
```{r}
OA_PLOS_Data <- cbind(OA_PLOS_Data, parse_names(OA_PLOS_Data$author_display_name))
```

Creating and applying a function that will clean and standardize important text columns. These columns will be used later for joining, so it is important to try and remove inconsistencies.
```{r}
# Create a standardizing function - removes all special characters
standardize_text <- function(x) {
  x <- as.character(x)
  
  x %>%
    stringi::stri_trans_general("Latin-ASCII") %>% # Remove special characters
    stringr::str_replace_all("[^A-Za-z0-9]+", "") %>% # Remove aLL non-alphanumeric characters
    tolower() %>% # Make text lowercase
    trimws() # Remove trailing and leading white space
}

# Select columns to standardize
cols_to_clean <- c("institution_display_name", "first_name", "last_name")

# Apply standardizing function and create combined variable
OA_PLOS_Data <- OA_PLOS_Data %>%
  mutate(across(all_of(cols_to_clean), standardize_text)) %>%
  mutate(combined_id = paste(first_name, last_name, institution_display_name, sep = "_"))
```

Save data to the intermediate-data directory.
```{r}
# write_csv(OA_PLOS_Data, file = here("data/intermediate-data/OA_PLOS_Hold.csv"))
```

Read in saved intermediate data.
```{r}
OA_PLOS_Data <- read_csv(here("data/intermediate-data/OA_PLOS_Hold.csv"), guess_max = 6000)
```

Filter to keep only corresponding authors
```{r}
OA_PLOS_Data <- OA_PLOS_Data %>%
  filter(is_corresponding == TRUE)
```

Clean intermediary objects from the environment.
```{r}
rm(PLOS_Comparator, PLOS_Main, cols_to_clean)
```

# NSERC Data Cleaning

Load the NSERC funding data.
```{r}
nserc_data <- readr::read_csv(
  here("data/raw-data/RAW_NSERC.csv"),
  col_types = readr::cols(.default = "c")
)    
```

Fixing encoding issues. Attempts to convert only problematic character values from latin1 to UTF-8, while leaving already-valid UTF-8 values unchanged.
```{r}
code_fix <- function(x) {
  
  # Only operate on character vectors
  if (!is.character(x)) return(x)

  # Check whether each element is valid UTF-8 (TRUE / FALSE / NA)
  ok <- stringi::stri_enc_isutf8(x)

  # Treat invalid or unknown encodings as needing conversion
  bad <- is.na(ok) | !ok

  # Fast exit if nothing needs fixing
  if (!any(bad)) return(x)

  # Convert only problematic elements
  y <- x
  y[bad] <- iconv(x[bad], from = "latin1", to = "UTF-8")

  # If conversion fails, keep original value
  y[is.na(y)] <- x[is.na(y)]

  y
}

# Apply the function
nserc_data <- nserc_data %>%
  dplyr::mutate(dplyr::across(everything(), code_fix))
```

Convert `FiscalYear` and `AwardAmount` to numeric.
```{r}
nserc_data <- nserc_data %>%
  mutate(FiscalYear = as.numeric(FiscalYear),
         AwardAmount = as.numeric(AwardAmount))
```

Use `parse_names()` to split recipient names into components.
```{r}
# Using format_reverse to prepare names for the parse_names function
nserc_data$`Name-Nom` <- humaniformat::format_reverse(nserc_data$`Name-Nom`)

# Splitting names into components
nserc_data <- cbind(nserc_data, parse_names(nserc_data$`Name-Nom`))

# Removing original name column
nserc_data <- select(nserc_data, -`Name-Nom`)
```

Use the function created above in the PLOS section to standardize important text columns.
```{r}
# Select columns to standardize
cols_to_clean2 <- c("Institution", "first_name", "last_name")

# Apply standardizing function and create combined variable
nserc_data <- nserc_data %>%
  mutate(across(all_of(cols_to_clean2), standardize_text)) %>%
  mutate(combined_id = paste(first_name, last_name, Institution, sep = "_"))
```

Summarize the funding information for every author.
```{r}
# Summaries for authors using firstname, lastname, and institution information
nserc_summary <- nserc_data %>%
  group_by(combined_id) %>%
  summarise(
    n_awards_NSERC = n(),
    total_amount_NSERC = sum(`AwardAmount`, na.rm = TRUE),
    oldest_year_NSERC = min(`FiscalYear`, na.rm = TRUE),
    newest_year_NSERC = max(`FiscalYear`, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(total_amount_NSERC))
```

# CIHR Data Cleaning

Load the CIHR funding data.
```{r}
cihr_data <- read_csv(here("data/raw-data/RAW_CIHR.csv"))
```

Using the code_fix function created earlier to convert only problematic character values from latin1 to UTF-8, while leaving already-valid UTF-8 values unchanged.
```{r}
# Apply the function
cihr_data <- cihr_data %>%
  dplyr::mutate(dplyr::across(everything(), code_fix))
```

Convert the CIHR_Contribution column to numeric, removing the `$` and `,`.
```{r}
cihr_data$CIHR_Contribution <- as.numeric(gsub("[\\$,]", "", cihr_data$CIHR_Contribution))
```

Extract grant year from Competition_CD (year is the first 4 digits)
```{r}
cihr_data$Year <- as.numeric(stringr::str_extract(cihr_data$Competition_CD, "^[0-9]{4}"))
```

CIHR Project grants can sometimes have multiple recipients associated with a single award. The first author is typically the main author. We will keep only the first author.
```{r}
# Keep only the first author (everything before the first semicolon)
cihr_data <- cihr_data %>% mutate(Name = trimws(sub(";.*", "", Name)))
```

Parse recipient names into separate components.
```{r}
# Using format_reverse to prepare names for the parse_names function
cihr_data$Name <- humaniformat::format_reverse(cihr_data$Name)

# Splitting names into components
cihr_data <- cbind(cihr_data, parse_names(cihr_data$Name))

# Removing original name column
cihr_data <- select(cihr_data, -Name)
```

Use the function created above in the PLOS section to standardize important text columns.
```{r}
# Select columns to standardize
cols_to_clean3 <- c("Institution_Paid", "first_name", "last_name")

# Apply standardizing function and create combined variable
cihr_data <- cihr_data %>%
  mutate(across(all_of(cols_to_clean3), standardize_text)) %>%
  mutate(combined_id = paste(first_name, last_name, Institution_Paid, sep = "_"))
```

Summarize the CIHR funding information for every author.
```{r}
# Summaries for clean (non-conflict) authors using first and last name
cihr_summary <- cihr_data %>%
  group_by(combined_id) %>%
  summarise(
    n_awards_CIHR = n(),
    total_amount_CIHR = sum(CIHR_Contribution, na.rm = TRUE),
    oldest_year_CIHR = min(Year, na.rm = TRUE),
    newest_year_CIHR = max(Year, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(total_amount_CIHR))
```

# Combining Data 

Combine all the author data together by the `combined_id` variable.
```{r}
# Removing unnecessary columns
OA_PLOS_Data <- OA_PLOS_Data %>%
  select(doi, combined_id)

# Joining data
author_data <- OA_PLOS_Data %>%
  left_join(nserc_summary, by = "combined_id") %>%
  left_join(cihr_summary, by = "combined_id")

# Remove rows without funding info
author_data <- author_data %>%
  filter(n_awards_NSERC > 0 | n_awards_CIHR > 0)
```

Adding author data to PLOS data.
```{r}
# Removing http info from the author doi column
author_data <- author_data %>%
  mutate(doi = sub("^https://doi.org/", "", doi))  %>%
  rename(DOI = doi)

# Joining data
PLOS_Data <- PLOS_Data %>%
  left_join(author_data, by = "DOI")

# Remove rows without funding info
PLOS_Data <- PLOS_Data %>%
  filter(n_awards_NSERC > 0 | n_awards_CIHR > 0)
```

We will also remove rows corresponding to publications that predate an authorâ€™s earliest CIHR or NSERC award. This results in a dataset that includes only publications with at least one author who received CIHR or NSERC funding prior to publishing the scored work.
```{r}
PLOS_Data <- PLOS_Data %>%
  filter(
    (!is.na(oldest_year_NSERC) & Publication_Year >= oldest_year_NSERC) |
    (!is.na(oldest_year_CIHR) & Publication_Year >= oldest_year_CIHR)
  )
```

Saving data.
```{r}
# write_csv(PLOS_Data, file = here("data/clean-data/Cleaned_Master_Data.csv"))
```